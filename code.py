# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sna-4Myniq8RM9BfJr6Bqifv1Cio_mPQ

Import Libraries
"""

import pandas as pd
import numpy as np
from numpy.random import seed
seed(7)
import seaborn as sns
import matplotlib.pyplot as plt
import statistics
from nltk.corpus import stopwords
from sklearn import preprocessing
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline, FeatureUnion
from sklearn.preprocessing import LabelBinarizer
from nltk.tokenize.toktok import ToktokTokenizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

"""Load Data"""

# Load rotten_tomatoes_reviews dataset.
rotten_tomatoes = pd.read_csv('rotten_tomatoes_reviews.tsv', sep='\t', encoding = 'ISO-8859-1')

# Rename, keep important columns of rotten_tomatoes_reviews dataset.
rotten_tomatoes.rename(columns={'fresh': 'sentiment'}, inplace=True)
rotten_tomatoes = rotten_tomatoes[['review','sentiment']]

"""Exploratory Data Analysis"""

# Summary of rotten_tomatoes_reviews dataset.
rotten_tomatoes.describe()

# Rotten_tomatoes sentiment count.
rotten_tomatoes['sentiment'].value_counts()

# Rotten_tomatoes unique values.
rotten_tomatoes['sentiment'].unique()

# Distribution of "fresh" vs "rotten" reviews.
sns.countplot(rotten_tomatoes['sentiment'])
plt.show()

# Check rotten_tomatoes_reviews dataset for missing values.
rotten_tomatoes.isnull().sum()

# Remove missing values.
rotten_tomatoes = rotten_tomatoes.dropna(subset=['review'])
rotten_tomatoes.isnull().sum()

# Checking for reviews with no text in rotten_tomatoes_reviews dataset.
blank_reviews = []

# (index, label, review text).
for i, label, review in rotten_tomatoes.itertuples():
    if type(review) == str:
        if review.isspace():
            blank_reviews.append(i)

# All remaining reviews contain text.
blank_reviews

# Addining in a new feature to rotten_tomatoes_reviews dataset to see if there is any correlation to the length of the review to the sentiment rating.
rotten_tomatoes['review length'] = rotten_tomatoes['review'].apply(lambda review: len(review))

# Visualization.
bins = 20
plt.hist(rotten_tomatoes[rotten_tomatoes['sentiment']=='fresh']['review length'],bins=bins,alpha=0.5)
plt.hist(rotten_tomatoes[rotten_tomatoes['sentiment']=='rotten']['review length'],bins=bins,alpha=0.5)
plt.legend(('fresh','rotten'))
plt.xlabel('review length', fontsize=12)
plt.ylabel('sentiment count', fontsize=12)
plt.show()

# Rename rotten tomatoes' labels to match imdb's labels.
rotten_tomatoes.sentiment = rotten_tomatoes.sentiment.replace(['fresh','rotten'],['positive','negative'])

"""Preprocessing for Machine Learning"""

# Splitting data into training and testing datasets.
X = rotten_tomatoes['review']
y = rotten_tomatoes['sentiment']

X_train_rotten, X_test_rotten, y_train_rotten, y_test_rotten = train_test_split(X, y, test_size=0.3, random_state=666, shuffle=True)

"""Logistic Regression"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_rotten_lr = Pipeline([('vect', CountVectorizer()), ('clf', LogisticRegression())])

# Fitting and generating predictions.
bow_rotten_lr.fit(X_train_rotten, y_train_rotten)
bow_y_pred_rotten_lr = bow_rotten_lr.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, bow_y_pred_rotten_lr))
print(confusion_matrix(y_test_rotten, bow_y_pred_rotten_lr))
print(accuracy_score(y_test_rotten, bow_y_pred_rotten_lr))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_rotten_lr = Pipeline([('features', FeatureUnion([('tfidf', TfidfVectorizer())])), ('clf', LogisticRegression())])

# Fitting and generating predictions.
tfidf_rotten_lr.fit(X_train_rotten, y_train_rotten)
tfidf_y_pred_rotten_lr = tfidf_rotten_lr.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, tfidf_y_pred_rotten_lr))
print(confusion_matrix(y_test_rotten, tfidf_y_pred_rotten_lr))
print(accuracy_score(y_test_rotten, tfidf_y_pred_rotten_lr))

"""Linear SVC"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_rotten_svc = Pipeline([('vect', CountVectorizer()), ('clf', LinearSVC())])

# Fitting and generating predictions.
bow_rotten_svc.fit(X_train_rotten, y_train_rotten)
bow_y_pred_rotten_svc = bow_rotten_svc.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, bow_y_pred_rotten_svc))
print(confusion_matrix(y_test_rotten, bow_y_pred_rotten_svc))
print(accuracy_score(y_test_rotten, bow_y_pred_rotten_svc))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_rotten_svc = Pipeline([('features', FeatureUnion([('tfidf', TfidfVectorizer())])), ('clf', LinearSVC())])

# Fitting and generating predictions.
tfidf_rotten_svc.fit(X_train_rotten, y_train_rotten)
tfidf_y_pred_rotten_svc = tfidf_rotten_svc.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, tfidf_y_pred_rotten_svc))
print(confusion_matrix(y_test_rotten, tfidf_y_pred_rotten_svc))
print(accuracy_score(y_test_rotten, tfidf_y_pred_rotten_svc))

"""Multinomial Naive Bayes"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_rotten_mnb = Pipeline([('features', FeatureUnion([('vect', CountVectorizer())])), ('clf', MultinomialNB())])

# Fitting and generating predictions.
bow_rotten_mnb.fit(X_train_rotten, y_train_rotten)
bow_y_pred_rotten_mnb = bow_rotten_mnb.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, bow_y_pred_rotten_mnb))
print(confusion_matrix(y_test_rotten, bow_y_pred_rotten_mnb))
print(accuracy_score(y_test_rotten, bow_y_pred_rotten_mnb))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_rotten_mnb = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])

# Fitting and generating predictions.
tfidf_rotten_mnb.fit(X_train_rotten, y_train_rotten)
tfidf_y_pred_rotten_mnb = tfidf_rotten_mnb.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, tfidf_y_pred_rotten_mnb))
print(confusion_matrix(y_test_rotten, tfidf_y_pred_rotten_mnb))
print(accuracy_score(y_test_rotten, tfidf_y_pred_rotten_mnb))

"""XGBoost"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_rotten_xgb = Pipeline([('vect', CountVectorizer()), ('clf', XGBClassifier())])

# Fitting and generating predictions.
bow_rotten_xgb.fit(X_train_rotten, y_train_rotten)
bow_y_pred_rotten_xgb = bow_rotten_xgb.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, bow_y_pred_rotten_xgb))
print(confusion_matrix(y_test_rotten, bow_y_pred_rotten_xgb))
print(accuracy_score(y_test_rotten, bow_y_pred_rotten_xgb))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_rotten_xgb = Pipeline([('tfidf', TfidfVectorizer()), ('clf', XGBClassifier())])

# Fitting and generating predictions.
tfidf_rotten_xgb.fit(X_train_rotten, y_train_rotten)
tfidf_y_pred_rotten_xgb = tfidf_rotten_xgb.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, tfidf_y_pred_rotten_xgb))
print(confusion_matrix(y_test_rotten, tfidf_y_pred_rotten_xgb))
print(accuracy_score(y_test_rotten, tfidf_y_pred_rotten_xgb))

"""Random Forest"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_rotten_rfc = Pipeline([('vect', CountVectorizer()), ('clf', RandomForestClassifier())])

# Fitting and generating predictions.
bow_rotten_rfc.fit(X_train_rotten, y_train_rotten)
bow_y_pred_rotten_rfc = bow_rotten_rfc.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, bow_y_pred_rotten_rfc))
print(confusion_matrix(y_test_rotten, bow_y_pred_rotten_rfc))
print(accuracy_score(y_test_rotten, bow_y_pred_rotten_rfc))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_rotten_rfc = Pipeline([('tfidf', TfidfVectorizer()), ('clf', RandomForestClassifier())])

# Fitting and generating predictions.
tfidf_rotten_rfc.fit(X_train_rotten, y_train_rotten)
tfidf_y_pred_rotten_rfc = tfidf_rotten_rfc.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, tfidf_y_pred_rotten_rfc))
print(confusion_matrix(y_test_rotten, tfidf_y_pred_rotten_rfc))
print(accuracy_score(y_test_rotten, tfidf_y_pred_rotten_rfc))

"""K-NN"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_rotten_knn = Pipeline([('vect', CountVectorizer()), ('clf', KNeighborsClassifier())])

# Fitting and generating predictions.
bow_rotten_knn.fit(X_train_rotten, y_train_rotten)
bow_y_pred_rotten_knn = bow_rotten_knn.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, bow_y_pred_rotten_knn))
print(confusion_matrix(y_test_rotten, bow_y_pred_rotten_knn))
print(accuracy_score(y_test_rotten, bow_y_pred_rotten_knn))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_rotten_knn = Pipeline([('tfidf', TfidfVectorizer()), ('clf', KNeighborsClassifier())])

# Fitting and generating predictions.
tfidf_rotten_knn.fit(X_train_rotten, y_train_rotten)
tfidf_y_pred_rotten_knn = tfidf_rotten_knn.predict(X_test_rotten)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_rotten, tfidf_y_pred_rotten_knn))
print(confusion_matrix(y_test_rotten, tfidf_y_pred_rotten_knn))
print(accuracy_score(y_test_rotten, tfidf_y_pred_rotten_knn))

"""Preprocessing for Deep Learning"""

rotten_sw = list(set(stopwords.words('english')))

# Containers for features and labels.
rotten_sentences = []
rotten_labels = []

for ind, row in rotten_tomatoes.iterrows():
    rotten_labels.append(row['sentiment'])
    rotten_sentence = row['review']

# Removing stop words.
    for word in rotten_sw: 
        token = " "+word+" "

# Replacing stop words with space.
        rotten_sentence = rotten_sentence.replace(token, " ") 
        rotten_sentence = rotten_sentence.replace(" ", " ")
    rotten_sentences.append(rotten_sentence)

# Label encoding labels.
enc = preprocessing.LabelEncoder()
rotten_encoded_labels = enc.fit_transform(rotten_labels)

# Model parameters.
vocab_size = 2000
embedding_dim = 16
max_length = 120
trunc_type='post'
padding_type='post'
oov_tok = "<OOV>"
training_portion = .7

# Train test split.

# Proportion of training dataset.
rotten_train_size = int(len(rotten_sentences) * training_portion)

# Training dataset.
rotten_train_sentences = rotten_sentences[:rotten_train_size]
rotten_train_labels = rotten_encoded_labels[:rotten_train_size]

# Testing dataset.
rotten_test_sentences = rotten_sentences[rotten_train_size:]
rotten_test_labels = rotten_encoded_labels[rotten_train_size:]

# Tokenizing, sequencing, padding features.
tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(rotten_train_sentences)
word_index = tokenizer.word_index

rotten_train_sequences = tokenizer.texts_to_sequences(rotten_train_sentences)
rotten_train_padded = pad_sequences(rotten_train_sequences, padding=padding_type, maxlen=max_length)

rotten_test_sequences = tokenizer.texts_to_sequences(rotten_test_sentences)
rotten_test_padded = pad_sequences(rotten_test_sequences, padding=padding_type, maxlen=max_length)

"""Word Embedding"""

# Model initialization.
word_embedding_rotten = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile model.
word_embedding_rotten.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Early stopping - Model checkpoint.
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1) 
mc = tf.keras.callbacks.ModelCheckpoint('best_model_word_embedding_rotten.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)

# Model summary.
word_embedding_rotten.summary()

# Model fit - training vs testing accuracy.
num_epochs = 4000
history = word_embedding_rotten.fit(rotten_train_padded, rotten_train_labels,
                                    validation_data=(rotten_test_padded, rotten_test_labels),
                                    epochs=num_epochs, verbose=1, callbacks=[es,mc])

# Load the best model.
best_model_word_embedding_rotten = tf.keras.models.load_model('best_model_word_embedding_rotten.h5')

# Accuracy of the best model.
word_embedding_rotten_accuracy = best_model_word_embedding_rotten.evaluate(rotten_test_padded, rotten_test_labels)

"""LSTM"""

# Model initialization.
lstm_rotten = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile model.
lstm_rotten.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Early stopping - Model checkpoint.
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1) 
mc = tf.keras.callbacks.ModelCheckpoint('best_model_lstm_rotten.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)

# Model summary.
lstm_rotten.summary()

# Model fit - training vs testing accuracy.
num_epochs = 4000
history_rotten = lstm_rotten.fit(rotten_train_padded, rotten_train_labels,
                          validation_data=(rotten_test_padded, rotten_test_labels),
                          epochs=num_epochs, verbose=1, callbacks=[es,mc])

# Load the best model.
best_model_lstm_rotten = tf.keras.models.load_model('best_model_lstm_rotten.h5')

# Accuracy of the best model.
lstm_rotten_accuracy = best_model_lstm_rotten.evaluate(rotten_test_padded, rotten_test_labels)

"""CNN"""

# Model initialization.
cnn_rotten = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.Conv1D(128, 5, activation='relu'),
    tf.keras.layers.GlobalMaxPooling1D(),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile model.
cnn_rotten.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Early stopping - Model checkpoint.
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1) 
mc = tf.keras.callbacks.ModelCheckpoint('best_model_cnn_rotten.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)

# Model summary.
cnn_rotten.summary()

# Model fit - training vs testing accuracy.
num_epochs = 4000
history = cnn_rotten.fit(rotten_train_padded, rotten_train_labels,
                         validation_data=(rotten_test_padded, rotten_test_labels),
                         epochs=num_epochs, verbose=1, callbacks=[es,mc])

# Load the best model.
best_model_cnn_rotten = tf.keras.models.load_model('best_model_cnn_rotten.h5')

# Accuracy of the best model.
cnn_rotten_accuracy = best_model_cnn_rotten.evaluate(rotten_test_padded, rotten_test_labels)

"""Model Comparison"""

# BoW Models.
x = ['K-NN BoW (baseline)', 'Random Forest BoW', 'XGBoost BoW', 'Multinomial Naive Bayes BoW', 'SVM BoW', 
     'Logistic Regression BoW']
y = [0.61,0.72,0.65,0.79,0.75,0.78]
plt.barh(x, y)
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# TF-IDF Models.
x = ['K-NN TF-IDF (baseline)', 'Random Forest TF-IDF', 'XGBoost TF-IDF', 'Multinomial Naive Bayes TF-IDF', 'SVM TF-IDF', 
     'Logistic Regression TF-IDF']
y = [0.71,0.71,0.66,0.74,0.78,0.78]
plt.barh(x, y, color=['r'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# BoW vs TF-IDF Models.
x = ['K-NN BoW', 'K-NN TF-IDF', 'Random Forest BoW', 'Random Forest TF-IDF', 'XGBoost BoW', 'XGBoost TF-IDF', 
     'Multinomial Naive Bayes BoW', 'Multinomial Naive Bayes TF-IDF', 'SVM BoW', 'SVM TF-IDF', 
     'Logistic Regression BoW', 'Logistic Regression TF-IDF']
y = [0.61,0.71,0.72,0.71,0.65,0.66,0.79,0.74,0.75,0.78,0.78,0.78]
plt.barh(x, y, color=['b','r','b','r','b','r','b','r','b','r','b','r'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# Deep Learning Models.
x = ['Word Embedding (baseline)', 'CNN', 'Bid-LSTM']
y = [0.73,0.73,0.73]
plt.barh(x, y, color=['g'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# All Models.
x = ['Word Embedding', 'CNN', 'Bid-LSTM', 'K-NN BoW', 'K-NN TF-IDF', 'Random Forest BoW', 
     'Random Forest TF-IDF', 'XGBoost BoW', 'XGBoost TF-IDF', 'Multinomial Naive Bayes BoW', 
     'Multinomial Naive Bayes TF-IDF', 'SVM BoW', 'SVM TF-IDF', 'Logistic Regression BoW', 
     'Logistic Regression TF-IDF']
y = [0.73,0.73,0.73,0.61,0.71,0.72,0.71,0.65,0.66,0.79,0.74,0.75,0.78,0.78,0.78]
plt.barh(x, y, color=['g','g','g','b','r','b','r','b','r','b','r','b','r','b','r'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

"""Load Data"""

# Load imdb_reviews dataset.
imdb = pd.read_csv('imdb_reviews.csv')

# Summary of imdb_reviews dataset.
imdb.describe()

# Imdb sentiment count.
imdb['sentiment'].value_counts()

# Imdb unique values.
imdb['sentiment'].unique()

# Distribution of "positive" vs "negative" reviews.
sns.countplot(imdb['sentiment'])
plt.show()

# Check imdb_reviews dataset for missing values.
imdb.isnull().sum()

# Checking for reviews with no text in imdb_reviews dataset.
blank_reviews = []

# (index, label, review text).
for i, label, review in imdb.itertuples():
    if type(review) == str:
        if review.isspace():
            blank_reviews.append(i)

# All remaining reviews contain text.
blank_reviews

# Addining in a new feature to imdb_reviews dataset to see if there is any correlation to the length of the review to the sentiment rating.
imdb['review length'] = imdb['review'].apply(lambda review: len(review))

# Visualization.
bins = 20
plt.hist(imdb[imdb['sentiment']=='positive']['review length'],bins=bins,alpha=0.5)
plt.hist(imdb[imdb['sentiment']=='negative']['review length'],bins=bins,alpha=0.5)
plt.legend(('positive','negative'))
plt.xlabel('review length', fontsize=12)
plt.ylabel('sentiment count', fontsize=12)
plt.xlim(right=6500)
plt.show()

"""Preprocessing for Machine Learning"""

# Splitting data into training and testing datasets.
X = imdb['review']
y = imdb['sentiment']

X_train_imdb, X_test_imdb, y_train_imdb, y_test_imdb = train_test_split(X, y, test_size=0.3, random_state=666)

"""Logistic Regression"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_imdb_lr = Pipeline([('features', FeatureUnion([('vect', CountVectorizer())])), ('clf', LogisticRegression())])

# Fitting and generating predictions.
bow_imdb_lr.fit(X_train_imdb, y_train_imdb)
bow_y_pred_imdb_lr = bow_imdb_lr.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, bow_y_pred_imdb_lr))
print(confusion_matrix(y_test_imdb, bow_y_pred_imdb_lr))
print(accuracy_score(y_test_imdb, bow_y_pred_imdb_lr))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_imdb_lr = Pipeline([('features', FeatureUnion([('tfidf', TfidfVectorizer())])), ('clf', LogisticRegression())])

# Fitting and generating predictions.
tfidf_imdb_lr.fit(X_train_imdb, y_train_imdb)
tfidf_y_pred_imdb_lr = tfidf_imdb_lr.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, tfidf_y_pred_imdb_lr))
print(confusion_matrix(y_test_imdb, tfidf_y_pred_imdb_lr))
print(accuracy_score(y_test_imdb, tfidf_y_pred_imdb_lr))

"""Linear SVC"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_imdb_svm = Pipeline([('vect', CountVectorizer()), ('clf', LinearSVC())])

# Fitting and generating predictions.
bow_imdb_svm.fit(X_train_imdb, y_train_imdb)
bow_y_pred_imdb_svm = bow_imdb_svm.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, bow_y_pred_imdb_svm))
print(confusion_matrix(y_test_imdb, bow_y_pred_imdb_svm))
print(accuracy_score(y_test_imdb, bow_y_pred_imdb_svm))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_imdb_svm = Pipeline([('features', FeatureUnion([('tfidf', TfidfVectorizer())])), ('clf', LinearSVC())])

# Fitting and generating predictions.
tfidf_imdb_svm.fit(X_train_imdb, y_train_imdb)
tfidf_y_pred_imdb_svm = tfidf_imdb_svm.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, tfidf_y_pred_imdb_svm))
print(confusion_matrix(y_test_imdb, tfidf_y_pred_imdb_svm))
print(accuracy_score(y_test_imdb, tfidf_y_pred_imdb_svm))

"""Multinomial Naive Bayes"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_imdb_mnb = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])

# Fitting and generating predictions.
bow_imdb_mnb.fit(X_train_imdb, y_train_imdb)
bow_y_pred_imdb_mnb = bow_imdb_mnb.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, bow_y_pred_imdb_mnb))
print(confusion_matrix(y_test_imdb, bow_y_pred_imdb_mnb))
print(accuracy_score(y_test_imdb, bow_y_pred_imdb_mnb))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_imdb_mnb = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])

# Fitting and generating predictions.
tfidf_imdb_mnb.fit(X_train_imdb, y_train_imdb)
tfidf_y_pred_imdb_mnb = tfidf_imdb_mnb.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, tfidf_y_pred_imdb_mnb))
print(confusion_matrix(y_test_imdb, tfidf_y_pred_imdb_mnb))
print(accuracy_score(y_test_imdb, tfidf_y_pred_imdb_mnb))

"""XGBoost"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_imdb_xgb = Pipeline([('vect', CountVectorizer()), ('clf', XGBClassifier())])

# Fitting and generating predictions.
bow_imdb_xgb.fit(X_train_imdb, y_train_imdb)
bow_y_pred_imdb_xgb = bow_imdb_xgb.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, bow_y_pred_imdb_xgb))
print(confusion_matrix(y_test_imdb, bow_y_pred_imdb_xgb))
print(accuracy_score(y_test_imdb, bow_y_pred_imdb_xgb))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_imdb_xgb = Pipeline([('tfidf', TfidfVectorizer()), ('clf', XGBClassifier())])

# Fitting and generating predictions.
tfidf_imdb_xgb.fit(X_train_imdb, y_train_imdb)
tfidf_y_pred_imdb_xgb = tfidf_imdb_xgb.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, tfidf_y_pred_imdb_xgb))
print(confusion_matrix(y_test_imdb, tfidf_y_pred_imdb_xgb))
print(accuracy_score(y_test_imdb, tfidf_y_pred_imdb_xgb))

"""Random Forest"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_imdb_rfc = Pipeline([('vect', CountVectorizer()), ('clf', RandomForestClassifier())])

# Fitting and generating predictions.
bow_imdb_rfc.fit(X_train_imdb, y_train_imdb)
bow_y_pred_imdb_rfc = bow_imdb_rfc.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, bow_y_pred_imdb_rfc))
print(confusion_matrix(y_test_imdb, bow_y_pred_imdb_rfc))
print(accuracy_score(y_test_imdb, bow_y_pred_imdb_rfc))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_imdb_rfc = Pipeline([('tfidf', TfidfVectorizer()), ('clf', RandomForestClassifier())])

# Fitting and generating predictions.
tfidf_imdb_rfc.fit(X_train_imdb, y_train_imdb)
tfidf_y_pred_imdb_rfc = tfidf_imdb_rfc.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, tfidf_y_pred_imdb_rfc))
print(confusion_matrix(y_test_imdb, tfidf_y_pred_imdb_rfc))
print(accuracy_score(y_test_imdb, tfidf_y_pred_imdb_rfc))

"""K-NN"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_imdb_knn = Pipeline([('vect', CountVectorizer()), ('clf', KNeighborsClassifier())])

# Fitting and generating predictions.
bow_imdb_knn.fit(X_train_imdb, y_train_imdb)
bow_y_pred_imdb_knn = bow_imdb_knn.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, bow_y_pred_imdb_knn))
print(confusion_matrix(y_test_imdb, bow_y_pred_imdb_knn))
print(accuracy_score(y_test_imdb, bow_y_pred_imdb_knn))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_imdb_knn = Pipeline([('tfidf', TfidfVectorizer()), ('clf', KNeighborsClassifier())])

# Fitting and generating predictions.
tfidf_imdb_knn.fit(X_train_imdb, y_train_imdb)
tfidf_y_pred_imdb_knn = tfidf_imdb_knn.predict(X_test_imdb)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test_imdb, tfidf_y_pred_imdb_knn))
print(confusion_matrix(y_test_imdb, tfidf_y_pred_imdb_knn))
print(accuracy_score(y_test_imdb, tfidf_y_pred_imdb_knn))

"""Preprocessing for Deep Learning"""

imdb_sw = list(set(stopwords.words('english')))

# Containers for features and labels.
imdb_sentences = []
imdb_labels = []

for ind, row in imdb.iterrows():
    imdb_labels.append(row['sentiment'])
    imdb_sentence = row['review']

# Removing stop words.
    for word in imdb_sw: 
        token = " "+word+" "
        
# Replacing stop words with space.
        imdb_sentence = imdb_sentence.replace(token, " ") 
        imdb_sentence = imdb_sentence.replace(" ", " ")
    imdb_sentences.append(imdb_sentence)

# Label encoding labels. 
enc = preprocessing.LabelEncoder()
imdb_encoded_labels = enc.fit_transform(imdb_labels)

# Model parameters.
vocab_size = 1000
embedding_dim = 16
max_length = 120
trunc_type='post'
padding_type='post'
oov_tok = "<OOV>"
training_portion = .7

# Train test split.

# Proportion of training dataset.
imdb_train_size = int(len(imdb_sentences) * training_portion)

# Training dataset.
imdb_train_sentences = imdb_sentences[:imdb_train_size]
imdb_train_labels = imdb_encoded_labels[:imdb_train_size]

# Testing dataset.
imdb_test_sentences = imdb_sentences[imdb_train_size:]
imdb_test_labels = imdb_encoded_labels[imdb_train_size:]

# Tokenizing, sequencing, padding features.
tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(imdb_train_sentences)
word_index = tokenizer.word_index

imdb_train_sequences = tokenizer.texts_to_sequences(imdb_train_sentences)
imdb_train_padded = pad_sequences(imdb_train_sequences, padding=padding_type, maxlen=max_length)

imdb_test_sequences = tokenizer.texts_to_sequences(imdb_test_sentences)
imdb_test_padded = pad_sequences(imdb_test_sequences, padding=padding_type, maxlen=max_length)

"""Word Embedding"""

# Model initialization.
word_embedding_imdb = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile model.
word_embedding_imdb.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Early stopping - Model checkpoint.
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1) 
mc = tf.keras.callbacks.ModelCheckpoint('best_model_word_embedding_imdb.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)

# Model summary.
word_embedding_imdb.summary()

# Model fit - training vs testing accuracy.
num_epochs = 4000
history = word_embedding_imdb.fit(imdb_train_padded, imdb_train_labels,
                                  validation_data=(imdb_test_padded, imdb_test_labels),
                                  epochs=num_epochs, verbose=1, callbacks=[es,mc])

# Load the best model.
best_model_word_embedding_imdb = tf.keras.models.load_model('best_model_word_embedding_imdb.h5')

# Accuracy of the best model.
word_embedding_imdb_accuracy = best_model_word_embedding_imdb.evaluate(imdb_test_padded, imdb_test_labels)

"""LSTM"""

# Model initialization.
lstm_imdb = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile model.
lstm_imdb.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Early stopping - Model checkpoint.
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1) 
mc = tf.keras.callbacks.ModelCheckpoint('best_model_lstm_imdb.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)

# Model summary.
lstm_imdb.summary()

# Model fit - training vs testing accuracy.
num_epochs = 4000
history_imdb = lstm_imdb.fit(imdb_train_padded, imdb_train_labels,
                        validation_data=(imdb_test_padded, imdb_test_labels),
                        epochs=num_epochs, verbose=1, callbacks=[es,mc])

# Load the best model.
best_model_lstm_imdb = tf.keras.models.load_model('best_model_lstm_imdb.h5')

# Accuracy of the best model.
lstm_imdb_accuracy = best_model_lstm_imdb.evaluate(imdb_test_padded, imdb_test_labels)

"""CNN"""

# Model initialization.
cnn_imdb = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.Conv1D(128, 5, activation='relu'),
    tf.keras.layers.GlobalMaxPooling1D(),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile model.
cnn_imdb.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Early stopping - Model checkpoint.
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1) 
mc = tf.keras.callbacks.ModelCheckpoint('best_model_cnn_imdb.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)

# Model summary.
cnn_imdb.summary()

# Model fit - training vs testing accuracy.
num_epochs = 4000
history = cnn_imdb.fit(imdb_train_padded, imdb_train_labels,
                       validation_data=(imdb_test_padded, imdb_test_labels),
                       epochs=num_epochs, verbose=1, callbacks=[es,mc])

# Load the best model.
best_model_cnn_imdb = tf.keras.models.load_model('best_model_cnn_imdb.h5')

# Accuracy of the best model.
cnn_imdb_accuracy = best_model_cnn_imdb.evaluate(imdb_test_padded, imdb_test_labels)

"""Model Comparison"""

# BoW Models.
x = ['K-NN BoW (baseline)', 'Random Forest BoW', 'XGBoost BoW', 'Multinomial Naive Bayes BoW', 'SVM BoW', 
     'Logistic Regression BoW']
y = [0.64,0.85,0.81,0.85,0.87,0.89]
plt.barh(x, y)
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# TF-IDF Models.
x = ['K-NN TF-IDF (baseline)', 'Random Forest TF-IDF', 'XGBoost TF-IDF', 'Multinomial Naive Bayes TF-IDF', 'SVM TF-IDF', 
     'Logistic Regression TF-IDF']
y = [0.76,0.84,0.81,0.86,0.90,0.90]
plt.barh(x, y, color=['r'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# BoW vs TF-IDF Models.
x = ['K-NN BoW', 'K-NN TF-IDF', 'Random Forest BoW', 'Random Forest TF-IDF', 'XGBoost BoW', 'XGBoost TF-IDF', 
     'Multinomial Naive Bayes BoW', 'Multinomial Naive Bayes TF-IDF', 'SVM BoW', 'SVM TF-IDF', 
     'Logistic Regression BoW', 'Logistic Regression TF-IDF']
y = [0.64,0.76,0.85,0.84,0.81,0.81,0.85,0.86,0.87,0.90,0.89,0.90]
plt.barh(x, y, color=['b','r','b','r','b','r','b','r','b','r','b','r'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# Deep Learning Models.
x = ['Word Embedding (baseline)', 'CNN', 'Bid-LSTM']
y = [0.86,0.86,0.85]
plt.barh(x, y, color=['g'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# All Models.
x = ['Word Embedding', 'CNN', 'Bid-LSTM', 'K-NN BoW', 'K-NN TF-IDF', 'Random Forest BoW', 
     'Random Forest TF-IDF', 'XGBoost BoW', 'XGBoost TF-IDF', 'Multinomial Naive Bayes BoW', 
     'Multinomial Naive Bayes TF-IDF', 'SVM BoW', 'SVM TF-IDF', 'Logistic Regression BoW', 
     'Logistic Regression TF-IDF']
y = [0.86,0.86,0.85,0.64,0.76,0.85,0.84,0.81,0.81,0.85,0.86,0.87,0.90,0.89,0.90]
plt.barh(x, y, color=['g','g','g','b','r','b','r','b','r','b','r','b','r','b','r'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

"""Merged Dataset"""

# Join the datasets.
frames = [rotten_tomatoes,imdb]
joined = pd.concat(frames)

"""Preprocessing for Machine Learning"""

X_train, X_test, y_train, y_test = train_test_split(joined.review, joined.sentiment, 
                                                    test_size=0.3, random_state=666, shuffle=True)

"""Logistic Regression"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_lr = Pipeline([('features', FeatureUnion([('vect', CountVectorizer())])), ('clf', LogisticRegression())])

# Fitting and generating predictions.
bow_lr.fit(X_train, y_train)
bow_y_pred_lr = bow_lr.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, bow_y_pred_lr))
print(confusion_matrix(y_test, bow_y_pred_lr))
print(accuracy_score(y_test, bow_y_pred_lr))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_lr = Pipeline([('features', FeatureUnion([('tfidf', TfidfVectorizer())])), ('clf', LogisticRegression())])

# Fitting and generating predictions.
tfidf_lr.fit(X_train, y_train)
tfidf_y_pred_lr = tfidf_lr.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, tfidf_y_pred_lr))
print(confusion_matrix(y_test, tfidf_y_pred_lr))
print(accuracy_score(y_test, tfidf_y_pred_lr))

"""Linear SVC"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_svm = Pipeline([('vect', CountVectorizer()), ('clf', LinearSVC())])

# Fitting and generating predictions.
bow_svm.fit(X_train, y_train)
bow_y_pred_svm = bow_svm.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, bow_y_pred_svm))
print(confusion_matrix(y_test, bow_y_pred_svm))
print(accuracy_score(y_test, bow_y_pred_svm))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_svm = Pipeline([('features', FeatureUnion([('tfidf', TfidfVectorizer())])), ('clf', LinearSVC())])

# Fitting and generating predictions.
tfidf_svm.fit(X_train, y_train)
tfidf_y_pred_svm = tfidf_svm.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, tfidf_y_pred_svm))
print(confusion_matrix(y_test, tfidf_y_pred_svm))
print(accuracy_score(y_test, tfidf_y_pred_svm))

"""Multinomial Naive Bayes"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_mnb = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])

# Fitting and generating predictions.
bow_mnb.fit(X_train, y_train)
bow_y_pred_mnb = bow_mnb.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, bow_y_pred_mnb))
print(confusion_matrix(y_test, bow_y_pred_mnb))
print(accuracy_score(y_test, bow_y_pred_mnb))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_mnb = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])

# Fitting and generating predictions.
tfidf_mnb.fit(X_train, y_train)
tfidf_y_pred_mnb = tfidf_mnb.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, tfidf_y_pred_mnb))
print(confusion_matrix(y_test, tfidf_y_pred_mnb))
print(accuracy_score(y_test, tfidf_y_pred_mnb))

"""XGBoost"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_xgb = Pipeline([('vect', CountVectorizer()), ('clf', XGBClassifier())])

# Fitting and generating predictions.
bow_xgb.fit(X_train, y_train)
bow_y_pred_xgb = bow_xgb.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, bow_y_pred_xgb))
print(confusion_matrix(y_test, bow_y_pred_xgb))
print(accuracy_score(y_test, bow_y_pred_xgb))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_xgb = Pipeline([('tfidf', TfidfVectorizer()), ('clf', XGBClassifier())])

# Fitting and generating predictions.
tfidf_xgb.fit(X_train, y_train)
tfidf_y_pred_xgb = tfidf_xgb.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, tfidf_y_pred_xgb))
print(confusion_matrix(y_test, tfidf_y_pred_xgb))
print(accuracy_score(y_test, tfidf_y_pred_xgb))

"""Random Forest"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_rfc = Pipeline([('vect', CountVectorizer()), ('clf', RandomForestClassifier())])

# Fitting and generating predictions.
bow_rfc.fit(X_train, y_train)
bow_y_pred_rfc = bow_rfc.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, bow_y_pred_rfc))
print(confusion_matrix(y_test, bow_y_pred_rfc))
print(accuracy_score(y_test, bow_y_pred_rfc))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_rfc = Pipeline([('tfidf', TfidfVectorizer()), ('clf', RandomForestClassifier())])

# Fitting and generating predictions.
tfidf_rfc.fit(X_train, y_train)
tfidf_y_pred_rfc = tfidf_rfc.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, tfidf_y_pred_rfc))
print(confusion_matrix(y_test, tfidf_y_pred_rfc))
print(accuracy_score(y_test, tfidf_y_pred_rfc))

"""K-NN"""

# Building a simple pipeline bag of words model to preprocess text data.
bow_knn = Pipeline([('vect', CountVectorizer()), ('clf', KNeighborsClassifier())])

# Fitting and generating predictions.
bow_knn.fit(X_train, y_train)
bow_y_pred_knn = bow_knn.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, bow_y_pred_knn))
print(confusion_matrix(y_test, bow_y_pred_knn))
print(accuracy_score(y_test, bow_y_pred_knn))

# Building a simple pipeline tf-idf model to preprocess text data.
tfidf_knn = Pipeline([('tfidf', TfidfVectorizer()), ('clf', KNeighborsClassifier())])

# Fitting and generating predictions.
tfidf_knn.fit(X_train, y_train)
tfidf_y_pred_knn = tfidf_knn.predict(X_test)

# Classification report, confusion matrix, accuracy.
print(classification_report(y_test, tfidf_y_pred_knn))
print(confusion_matrix(y_test, tfidf_y_pred_knn))
print(accuracy_score(y_test, tfidf_y_pred_knn))

"""Preprocessing for Deep Learning"""

sw = list(set(stopwords.words('english')))

# Containers for features and labels.
sentences = []
labels = []

for ind, row in joined.iterrows():
    labels.append(row['sentiment'])
    sentence = row['review']
# Removing stop words.
    for word in sw: 
        token = " "+word+" "
# Replacing stop words with space.
        sentence = sentence.replace(token, " ") 
        sentence = sentence.replace(" ", " ")
    sentences.append(sentence)

# Label encoding labels.
enc = preprocessing.LabelEncoder()
encoded_labels = enc.fit_transform(labels)

# Model parameters.
vocab_size = 1000
embedding_dim = 16
max_length = 120
trunc_type='post'
padding_type='post'
oov_tok = "<OOV>"
training_portion = .7

# Train test split.

# Proportion of training dataset.
train_size = int(len(sentences) * training_portion)

# Training dataset.
train_sentences = sentences[:train_size]
train_labels = encoded_labels[:train_size]

# Testing dataset.
testing_sentences = sentences[train_size:]
testing_labels = encoded_labels[train_size:]

# Tokenizing, sequencing, padding features.
tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(train_sentences)
word_index = tokenizer.word_index

train_sequences = tokenizer.texts_to_sequences(train_sentences)
train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)

testing_sequences = tokenizer.texts_to_sequences(testing_sentences)
testing_padded = pad_sequences(testing_sequences, padding=padding_type, maxlen=max_length)

"""Word Embedding Model"""

# Model initialization.
word_embedding = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile model.
word_embedding.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Early stopping - Model checkpoint.
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1) 
mc = tf.keras.callbacks.ModelCheckpoint('best_model_word_embedding.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)

# Model summary.
word_embedding.summary()

# Model fit - training vs testing accuracy.
num_epochs = 4000
history = word_embedding.fit(train_padded, train_labels,
                             validation_data=(testing_padded, testing_labels),
                             epochs=num_epochs, verbose=1, callbacks=[es,mc])

# Load the best model.
best_model_word_embedding = tf.keras.models.load_model('best_model_word_embedding.h5')

# Accuracy of the best model.
word_embedding_accuracy = best_model_word_embedding.evaluate(testing_padded, testing_labels)

"""Bidirectional - LSTM Model"""

# Model initialization.
lstm = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile model.
lstm.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Early stopping - Model checkpoint.
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1) 
mc = tf.keras.callbacks.ModelCheckpoint('best_model_lstm.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)

# Model summary.
lstm.summary()

# Model fit - training vs testing accuracy.
num_epochs = 4000
history_merged = lstm.fit(train_padded, train_labels,
                   validation_data=(testing_padded, testing_labels),
                   epochs=num_epochs, verbose=1, callbacks=[es,mc])

# Load the best model.
best_model_lstm = tf.keras.models.load_model('best_model_lstm.h5')

# Accuracy of the best model.
lstm_accuracy = best_model_lstm.evaluate(testing_padded, testing_labels)

"""CNN Model"""

# Model initialization.
cnn = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.Conv1D(128, 5, activation='relu'),
    tf.keras.layers.GlobalMaxPooling1D(),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile model.
cnn.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Early stopping - Model checkpoint.
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1) 
mc = tf.keras.callbacks.ModelCheckpoint('best_model_cnn.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)

# Model summary.
cnn.summary()

# Model fit - training vs testing accuracy.
num_epochs = 4000
history = cnn.fit(train_padded, train_labels,
                  validation_data=(testing_padded, testing_labels),
                  epochs=num_epochs, verbose=1, callbacks=[es,mc])

# Load the best model.
best_model_cnn = tf.keras.models.load_model('best_model_cnn.h5')

# Accuracy of the best model.
cnn_accuracy = best_model_cnn.evaluate(testing_padded, testing_labels)

"""Model Comparison"""

# BoW Models.
x = ['K-NN BoW (baseline)', 'Random Forest BoW', 'XGBoost BoW', 'Multinomial Naive Bayes BoW', 'SVM BoW', 
     'Logistic Regression BoW']
y = [0.62,0.79,0.73,0.80,0.80,0.83]
plt.barh(x, y)
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# TF-IDF Models.
x = ['K-NN TF-IDF (baseline)', 'Random Forest TF-IDF', 'XGBoost TF-IDF', 'Multinomial Naive Bayes TF-IDF', 'SVM TF-IDF', 
     'Logistic Regression TF-IDF']
y = [0.72,0.78,0.73,0.81,0.84,0.84]
plt.barh(x, y, color=['r'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# BoW vs TF-IDF Models.
x = ['K-NN BoW', 'K-NN TF-IDF', 'Random Forest BoW', 'Random Forest TF-IDF', 'XGBoost BoW', 'XGBoost TF-IDF', 
     'Multinomial Naive Bayes BoW', 'Multinomial Naive Bayes TF-IDF', 'SVM BoW', 'SVM TF-IDF', 
     'Logistic Regression BoW', 'Logistic Regression TF-IDF']
y = [0.62,0.72,0.79,0.78,0.73,0.73,0.80,0.81,0.80,0.84,0.83,0.84]
plt.barh(x, y, color=['b','r','b','r','b','r','b','r','b','r','b','r'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# Deep Learning Models.
x = ['Word Embedding (baseline)', 'CNN', 'Bid-LSTM']
y = [0.86,0.86,0.86]
plt.barh(x, y, color=['g'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# All Models.
x = ['Word Embedding', 'CNN', 'Bid-LSTM', 'K-NN BoW', 'K-NN TF-IDF', 'Random Forest BoW', 
     'Random Forest TF-IDF', 'XGBoost BoW', 'XGBoost TF-IDF', 'Multinomial Naive Bayes BoW', 
     'Multinomial Naive Bayes TF-IDF', 'SVM BoW', 'SVM TF-IDF', 'Logistic Regression BoW', 
     'Logistic Regression TF-IDF']
y = [0.86,0.86,0.86,0.62,0.72,0.79,0.78,0.73,0.73,0.80,0.81,0.80,0.84,0.83,0.84]
plt.barh(x, y, color=['g','g','g','b','r','b','r','b','r','b','r','b','r','b','r'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

"""Best Models - Machine Learning"""

# Logistic Regression Models.
x = ['Logistic Regression IMDB BoW', 'Logistic Regression IMDB TF-IDF', 'Logistic Regression Rotten BoW', 
     'Logistic Regression Rotten TF-IDF', 'Logistic Regression Merged BoW', 'Logistic Regression Merged TF-IDF']
y = [0.89,0.9,0.78,0.78,0.83,0.84]
plt.barh(x, y, color=['b','r','b','r','b','r','b','r'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

# SVM Models.
x = ['SVM IMDB BoW', 'SVM IMDB TF-IDF', 'SVM Rotten BoW', 'SVM Rotten TF-IDF', 'SVM Merged BoW', 'SVM Merged TF-IDF']
y = [0.87,0.9,0.75,0.78,0.8,0.84]
plt.barh(x, y, color=['b','r','b','r','b','r','b','r'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

"""Best Model - Deep Learning"""

# Bid-LSTM Models.
x = ['Bid-LSTM IMDB', 'Bid-LSTM Rotten', 'Bid-LSTM Merged']
y = [0.85,0.73,0.86]
plt.barh(x, y, color=['g','g','g'])
for index, value in enumerate(y):
    plt.text(value, index, str(value))
plt.show()

"""Interpreting the Results

Feature Importance - IMDB - Top Models
"""

# Logistic Regression - BoW model.

# Importance.
importance_bow_lr_imdb = bow_imdb_lr.named_steps['clf'].coef_[0]

# Sort by index.
indices_bow_lr_imdb = np.argsort(importance_bow_lr_imdb)

# Keep top 20 positive words.
positive_bow_lr_imdb = importance_bow_lr_imdb[indices_bow_lr_imdb[-20:]]

# Keep top 20 negative words.
negative_bow_lr_imdb = importance_bow_lr_imdb[indices_bow_lr_imdb[:20]]

# All together.
top_coefficients_bow_lr_imdb = np.hstack([positive_bow_lr_imdb, negative_bow_lr_imdb])

# Convert to features' names.
feature_names = bow_imdb_lr.named_steps['features'].get_feature_names()
feature_names = np.asanyarray(feature_names)
top_positive_bow_lr_imdb = feature_names[indices_bow_lr_imdb[-20:]]
top_negative_bow_lr_imdb = feature_names[indices_bow_lr_imdb[:20]]
top_features_bow_lr_imdb = np.hstack([top_positive_bow_lr_imdb, top_negative_bow_lr_imdb])

# Plot them.
plt.figure(figsize=(15, 5))
colors = ['red' if c < 0 else 'blue' for c in top_coefficients_bow_lr_imdb]
plt.bar(np.arange(2 * 20), top_coefficients_bow_lr_imdb, color=colors)
plt.xticks(np.arange(1, 1 + 2 * 20), top_features_bow_lr_imdb, rotation=60, ha='right')
plt.show()

# Logistic Regression - TF-IDF model.

# Importance.
importance_tfidf_lr_imdb = tfidf_imdb_lr.named_steps['clf'].coef_[0]

# Sort by index.
indices_tfidf_lr_imdb = np.argsort(importance_tfidf_lr_imdb)

# Keep top 20 positive words.
positive_tfidf_lr_imdb = importance_tfidf_lr_imdb[indices_tfidf_lr_imdb[-20:]]

# Keep top 20 negative words.
negative_tfidf_lr_imdb = importance_tfidf_lr_imdb[indices_tfidf_lr_imdb[:20]]

# All together.
top_coefficients_tfidf_lr_imdb = np.hstack([positive_tfidf_lr_imdb, negative_tfidf_lr_imdb])

# Convert to features' names.
feature_names = tfidf_imdb_lr.named_steps['features'].get_feature_names()
feature_names = np.asanyarray(feature_names)
top_positive_tfidf_lr_imdb = feature_names[indices_tfidf_lr_imdb[-20:]]
top_negative_tfidf_lr_imdb = feature_names[indices_tfidf_lr_imdb[:20]]
top_features_tfidf_lr_imdb = np.hstack([top_positive_tfidf_lr_imdb, top_negative_tfidf_lr_imdb])

# Plot them.
plt.figure(figsize=(15, 5))
colors = ['red' if c < 0 else 'blue' for c in top_coefficients_tfidf_lr_imdb]
plt.bar(np.arange(2 * 20), top_coefficients_tfidf_lr_imdb, color=colors)
plt.xticks(np.arange(1, 1 + 2 * 20), top_features_tfidf_lr_imdb, rotation=60, ha='right')
plt.show()

# SVM - TF-IDF model.

# Importance.
importance_tfidf_svm_imdb = tfidf_imdb_svm.named_steps['clf'].coef_[0]

# Sort by index.
indices_tfidf_svm_imdb = np.argsort(importance_tfidf_svm_imdb)

# Keep top 20 positive words.
positive_tfidf_svm_imdb = importance_tfidf_svm_imdb[indices_tfidf_svm_imdb[-20:]]

# Keep top 20 negative words.
negative_tfidf_svm_imdb = importance_tfidf_svm_imdb[indices_tfidf_svm_imdb[:20]]

# All together.
top_coefficients_tfidf_svm_imdb = np.hstack([positive_tfidf_svm_imdb, negative_tfidf_svm_imdb])

# Convert to features' names.
feature_names = tfidf_imdb_svm.named_steps['features'].get_feature_names()
feature_names = np.asanyarray(feature_names)
top_positive_tfidf_svm_imdb = feature_names[indices_tfidf_svm_imdb[-20:]]
top_negative_tfidf_svm_imdb = feature_names[indices_tfidf_svm_imdb[:20]]
top_features_tfidf_svm_imdb = np.hstack([top_positive_tfidf_svm_imdb, top_negative_tfidf_svm_imdb])

# Plot them.
plt.figure(figsize=(15, 5))
colors = ['red' if c < 0 else 'blue' for c in top_coefficients_tfidf_svm_imdb]
plt.bar(np.arange(2 * 20), top_coefficients_tfidf_svm_imdb, color=colors)
plt.xticks(np.arange(1, 1 + 2 * 20), top_features_tfidf_svm_imdb, rotation=60, ha='right')
plt.show()

"""Feature Importance - Rotten Tomatoes - Top Models"""

# Multinomial Naive Bayes - BoW model.

# Importance.
importance_bow_mnb_rotten = bow_rotten_mnb.named_steps['clf'].coef_[0]

# Sort by index.
indices_bow_mnb_rotten = np.argsort(importance_bow_mnb_rotten)

# Keep top 20 positive words.
positive_bow_mnb_rotten = importance_bow_mnb_rotten[indices_bow_mnb_rotten[-20:]]

# Keep top 20 negative words.
negative_bow_mnb_rotten = importance_bow_mnb_rotten[indices_bow_mnb_rotten[:20]]

# All together.
top_coefficients_bow_mnb_rotten = np.hstack([positive_bow_mnb_rotten, negative_bow_mnb_rotten])

# Convert to features' names.
feature_names = bow_rotten_mnb.named_steps['features'].get_feature_names()
feature_names = np.asanyarray(feature_names)
top_positive_bow_mnb_rotten = feature_names[indices_bow_mnb_rotten[-20:]]
top_negative_bow_mnb_rotten = feature_names[indices_bow_mnb_rotten[:20]]
top_features_bow_mnb_rotten = np.hstack([top_positive_bow_mnb_rotten, top_negative_bow_mnb_rotten])

# Plot them.
plt.figure(figsize=(15, 5))
colors = ['red' if c < 0 else 'blue' for c in top_coefficients_bow_mnb_rotten]
plt.bar(np.arange(2 * 20), top_coefficients_bow_mnb_rotten, color=colors)
plt.xticks(np.arange(1, 1 + 2 * 20), top_features_bow_mnb_rotten, rotation=60, ha='right')
plt.show()

# Logistic Regression - TF-IDF model.

# Importance.
importance_tfidf_lr_rotten = tfidf_rotten_lr.named_steps['clf'].coef_[0]

# Sort by index.
indices_tfidf_lr_rotten = np.argsort(importance_tfidf_lr_rotten)

# Keep top 20 positive words.
positive_tfidf_lr_rotten = importance_tfidf_lr_rotten[indices_tfidf_lr_rotten[-20:]]

# Keep top 20 negative words.
negative_tfidf_lr_rotten = importance_tfidf_lr_rotten[indices_tfidf_lr_rotten[:20]]

# All together.
top_coefficients_tfidf_lr_rotten = np.hstack([positive_tfidf_lr_rotten, negative_tfidf_lr_rotten])

# Convert to features' names.
feature_names = tfidf_rotten_lr.named_steps['features'].get_feature_names()
feature_names = np.asanyarray(feature_names)
top_positive_tfidf_lr_rotten = feature_names[indices_tfidf_lr_rotten[-20:]]
top_negative_tfidf_lr_rotten = feature_names[indices_tfidf_lr_rotten[:20]]
top_features_tfidf_lr_rotten = np.hstack([top_positive_tfidf_lr_rotten, top_negative_tfidf_lr_rotten])

# Plot them.
plt.figure(figsize=(15, 5))
colors = ['red' if c < 0 else 'blue' for c in top_coefficients_tfidf_lr_rotten]
plt.bar(np.arange(2 * 20), top_coefficients_tfidf_lr_rotten, color=colors)
plt.xticks(np.arange(1, 1 + 2 * 20), top_features_tfidf_lr_rotten, rotation=60, ha='right')
plt.show()

# SVM - TF-IDF model.

# Importance.
importance_tfidf_svm_rotten = tfidf_rotten_svc.named_steps['clf'].coef_[0]

# Sort by index.
indices_tfidf_svm_rotten = np.argsort(importance_tfidf_svm_rotten)

# Keep top 20 positive words.
positive_tfidf_svm_rotten = importance_tfidf_svm_rotten[indices_tfidf_svm_rotten[-20:]]

# Keep top 20 negative words.
negative_tfidf_svm_rotten = importance_tfidf_svm_rotten[indices_tfidf_svm_rotten[:20]]

# All together.
top_coefficients_tfidf_svm_rotten = np.hstack([positive_tfidf_svm_rotten, negative_tfidf_svm_rotten])

# Convert to features' names.
feature_names = tfidf_rotten_svc.named_steps['features'].get_feature_names()
feature_names = np.asanyarray(feature_names)
top_positive_tfidf_svm_rotten = feature_names[indices_tfidf_svm_rotten[-20:]]
top_negative_tfidf_svm_rotten = feature_names[indices_tfidf_svm_rotten[:20]]
top_features_tfidf_svm_rotten = np.hstack([top_positive_tfidf_svm_rotten, top_negative_tfidf_svm_rotten])

# Plot them.
plt.figure(figsize=(15, 5))
colors = ['red' if c < 0 else 'blue' for c in top_coefficients_tfidf_svm_rotten]
plt.bar(np.arange(2 * 20), top_coefficients_tfidf_svm_rotten, color=colors)
plt.xticks(np.arange(1, 1 + 2 * 20), top_features_tfidf_svm_rotten, rotation=60, ha='right')
plt.show()

"""Feature Importance - Merged Dataset - Top Models"""

# Logistic Regression - BoW model.

# Importance.
importance_bow_lr = bow_lr.named_steps['clf'].coef_[0]

# Sort by index.
indices_bow_lr = np.argsort(importance_bow_lr)

# Keep top 20 positive words.
positive_bow_lr = importance_bow_lr[indices_bow_lr[-20:]]

# Keep top 20 negative words.
negative_bow_lr = importance_bow_lr[indices_bow_lr[:20]]

# All together.
top_coefficients_bow_lr = np.hstack([positive_bow_lr, negative_bow_lr])

# Convert to features' names.
feature_names = bow_lr.named_steps['features'].get_feature_names()
feature_names = np.asanyarray(feature_names)
top_positive_bow_lr = feature_names[indices_bow_lr[-20:]]
top_negative_bow_lr = feature_names[indices_bow_lr[:20]]
top_features_bow_lr = np.hstack([top_positive_bow_lr, top_negative_bow_lr])

# Plot them.
plt.figure(figsize=(15, 5))
colors = ['red' if c < 0 else 'blue' for c in top_coefficients_bow_lr]
plt.bar(np.arange(2 * 20), top_coefficients_bow_lr, color=colors)
plt.xticks(np.arange(1, 1 + 2 * 20), top_features_bow_lr, rotation=60, ha='right')
plt.show()

# Logistic Regression - TF-IDF model.

# Importance.
importance_tfidf_lr = tfidf_lr.named_steps['clf'].coef_[0]

# Sort by index.
indices_tfidf_lr = np.argsort(importance_tfidf_lr)

# Keep top 20 positive words.
positive_tfidf_lr = importance_tfidf_lr[indices_tfidf_lr[-20:]]

# Keep top 20 negative words.
negative_tfidf_lr = importance_tfidf_lr[indices_tfidf_lr[:20]]

# All together.
top_coefficients_tfidf_lr = np.hstack([positive_tfidf_lr, negative_tfidf_lr])

# Convert to features' names.
feature_names = tfidf_lr.named_steps['features'].get_feature_names()
feature_names = np.asanyarray(feature_names)
top_positive_tfidf_lr = feature_names[indices_tfidf_lr[-20:]]
top_negative_tfidf_lr = feature_names[indices_tfidf_lr[:20]]
top_features_tfidf_lr = np.hstack([top_positive_tfidf_lr, top_negative_tfidf_lr])

# Plot them.
plt.figure(figsize=(15, 5))
colors = ['red' if c < 0 else 'blue' for c in top_coefficients_tfidf_lr]
plt.bar(np.arange(2 * 20), top_coefficients_tfidf_lr, color=colors)
plt.xticks(np.arange(1, 1 + 2 * 20), top_features_tfidf_lr, rotation=60, ha='right')
plt.show()

# SVM - TF-IDF model.

# Importance.
importance_tfidf_svm = tfidf_svm.named_steps['clf'].coef_[0]

# Sort by index.
indices_tfidf_svm = np.argsort(importance_tfidf_svm)

# Keep top 20 positive words.
positive_tfidf_svm = importance_tfidf_svm[indices_tfidf_svm[-20:]]

# Keep top 20 negative words.
negative_tfidf_svm = importance_tfidf_svm[indices_tfidf_svm[:20]]

# All together.
top_coefficients_tfidf_svm = np.hstack([positive_tfidf_svm, negative_tfidf_svm])

# Convert to features' names.
feature_names = tfidf_svm.named_steps['features'].get_feature_names()
feature_names = np.asanyarray(feature_names)
top_positive_tfidf_svm = feature_names[indices_tfidf_svm[-20:]]
top_negative_tfidf_svm = feature_names[indices_tfidf_svm[:20]]
top_features_tfidf_svm = np.hstack([top_positive_tfidf_svm, top_negative_tfidf_svm])

# Plot them.
plt.figure(figsize=(15, 5))
colors = ['red' if c < 0 else 'blue' for c in top_coefficients_tfidf_svm]
plt.bar(np.arange(2 * 20), top_coefficients_tfidf_svm, color=colors)
plt.xticks(np.arange(1, 1 + 2 * 20), top_features_tfidf_svm, rotation=60, ha='right')
plt.show()

"""Accuracy vs Loss Plots - IMDB - Bid-LSTM"""

# Loss and Accuracy Plots.

plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.plot(history_imdb.history['accuracy'], label='Training Accuracy')
plt.plot(history_imdb.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel("Epochs")
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_imdb.history['loss'], label='Training Loss')
plt.plot(history_imdb.history['val_loss'], label='Validation Loss')
plt.xlabel("Epochs")
plt.ylabel('Loss')
plt.legend()

plt.show()

"""Accuracy vs Loss Plots - Rotten Tomatoes - Bid-LSTM"""

# Loss and Accuracy Plots.

plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.plot(history_rotten.history['accuracy'], label='Training Accuracy')
plt.plot(history_rotten.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel("Epochs")
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_rotten.history['loss'], label='Training Loss')
plt.plot(history_rotten.history['val_loss'], label='Validation Loss')
plt.xlabel("Epochs")
plt.ylabel('Loss')
plt.legend()

plt.show()

"""Accuracy vs Loss Plots - Merged Dataset - Bid-LSTM"""

# Loss and Accuracy Plots.

plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.plot(history_merged.history['accuracy'], label='Training Accuracy')
plt.plot(history_merged.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel("Epochs")
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_merged.history['loss'], label='Training Loss')
plt.plot(history_merged.history['val_loss'], label='Validation Loss')
plt.xlabel("Epochs")
plt.ylabel('Loss')
plt.legend()

plt.show()